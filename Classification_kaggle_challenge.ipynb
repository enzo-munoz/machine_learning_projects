{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMSsFR79ftBWAs8IJ5cear"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FtGiQwbvbLKZ"},"outputs":[],"source":["# Import required libraries\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import IsolationForest  # For outlier detection\n"]},{"cell_type":"code","source":["\n","# Load the datasets\n","train_df = pd.read_csv('train_set.csv')\n","test_df = pd.read_csv('test_set.csv')\n","\n","# Extract features and target\n","features = [col for col in train_df.columns if col not in ['ID', 'target']]\n","X = train_df[features]\n","y = train_df['target']\n","test_X = test_df[features]\n","test_ids = test_df['ID']\n","\n","# Handle missing values\n","imputer = SimpleImputer(strategy='mean')\n","X = pd.DataFrame(imputer.fit_transform(X), columns=features)\n","test_X = pd.DataFrame(imputer.transform(test_X), columns=features)\n","contaminations = [0.01, 0.05, 0.1]\n","# Outlier detection and removal\n","for elt in contaminations:\n","  outlier_detector = IsolationForest(contamination=0.05, random_state=42)\n","  outlier_mask = outlier_detector.fit_predict(X) == 1\n","  X = X[outlier_mask]\n","  y = y[outlier_mask]\n","\n","  # Split the data into training and validation sets\n","  X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","  # Define a comprehensive parameter grid\n","  param_grid = {\n","      'k_best__k': [10, 15, 17, 20, 22],            # More options for feature selection\n","      'pca__n_components': [0.85, 0.9, 0.925, 0.95, 0.975, 0.99],   # Finer granularity for PCA retained variance\n","      'model__C': [0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000],   # More detailed range of regularization\n","      'model__gamma': [1e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 0.5, 1]  # Finer steps for kernel coefficient\n","  }\n","\n","\n","  # Create a pipeline\n","  pipeline = Pipeline([\n","      ('scaler', RobustScaler()),        # Scale the features\n","      ('k_best', SelectKBest(score_func=f_classif)),  # Feature selection\n","      ('pca', PCA()),                    # Dimensionality reduction\n","      ('model', SVC(kernel='rbf', random_state=42))  # Non-linear SVM classifier\n","  ])\n","\n","  # Perform grid search\n","  grid_search = GridSearchCV(\n","      pipeline,\n","      param_grid,\n","      cv=5,                              # Cross-validation folds\n","      scoring='accuracy',\n","      verbose=2,\n","      n_jobs=-1                          # Use all CPU cores\n","  )\n","  grid_search.fit(X_train, y_train)\n","\n","# Evaluate on validation set\n","best_model = grid_search.best_estimator_\n","y_val_pred = best_model.predict(X_val)\n","accuracy = accuracy_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy with optimized pipeline: {accuracy}\")\n","print(\"Best Parameters:\", grid_search.best_params_)\n","\n","# Train the final model on the entire dataset\n","final_X_selected = X\n","best_model.fit(final_X_selected, y)\n","test_predictions = best_model.predict(test_X)\n","\n","# Save predictions to a CSV file\n","output_df = pd.DataFrame({'ID': test_ids, 'target': test_predictions})\n","output_filename = 'non_linear_svm_predictions_extensive_search.csv'\n","output_df.to_csv(output_filename, index=False)\n","\n","print(f\"Predictions saved to '{output_filename}' with {len(output_df)} rows.\")"],"metadata":{"id":"p1d8_fWfbT7P"},"execution_count":null,"outputs":[]}]}